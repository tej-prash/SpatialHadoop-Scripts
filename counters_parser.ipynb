{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1\n",
      "                        map_time(ms) reduce_time(ms) total_time(s)  \\\n",
      "Size(GB)                                                             \n",
      "30GB grid index skyline       459882           23305          58.2   \n",
      "40GB grid index skyline       483697           28984        58.853   \n",
      "50GB grid index skyline       554075           31692        62.062   \n",
      "60GB grid index skyline       601586           29041        69.469   \n",
      "70GB grid index skyline       640804           39060        73.034   \n",
      "\n",
      "                        cpu_time(ms) diff_time(s) map_start_diff(s)  \\\n",
      "Size(GB)                                                              \n",
      "30GB grid index skyline       256330           15                15   \n",
      "40GB grid index skyline       287180           11                12   \n",
      "50GB grid index skyline       334030            9                 9   \n",
      "60GB grid index skyline       350640           14                14   \n",
      "70GB grid index skyline       394420           13                13   \n",
      "\n",
      "                        map_end_diff(s) filter_end_diff(s)  \\\n",
      "Size(GB)                                                     \n",
      "30GB grid index skyline              59                  4   \n",
      "40GB grid index skyline              60                  3   \n",
      "50GB grid index skyline              63                  3   \n",
      "60GB grid index skyline              70                  4   \n",
      "70GB grid index skyline              72                  3   \n",
      "\n",
      "                                    application_number  \n",
      "Size(GB)                                                \n",
      "30GB grid index skyline  application1552397085974_0001  \n",
      "40GB grid index skyline  application1552397085974_0002  \n",
      "50GB grid index skyline  application1552397085974_0005  \n",
      "60GB grid index skyline  application1552397085974_0007  \n",
      "70GB grid index skyline  application1552397085974_0009  \n",
      "test2\n",
      "                        map_time(ms) reduce_time(ms) total_time(s)  \\\n",
      "Size(GB)                                                             \n",
      "30GB grid index skyline       435740           20375        52.835   \n",
      "40GB grid index skyline       498285           25262        53.728   \n",
      "50GB grid index skyline       571973           25668        66.004   \n",
      "60GB grid index skyline       572114           35173         62.92   \n",
      "70GB grid index skyline       652571           41595        71.799   \n",
      "\n",
      "                        cpu_time(ms) diff_time(s) map_start_diff(s)  \\\n",
      "Size(GB)                                                              \n",
      "30GB grid index skyline       258340           13                13   \n",
      "40GB grid index skyline       285000            9                 9   \n",
      "50GB grid index skyline       333700           13                13   \n",
      "60GB grid index skyline       348150            9                 9   \n",
      "70GB grid index skyline       396220            9                 9   \n",
      "\n",
      "                        map_end_diff(s) filter_end_diff(s)  \\\n",
      "Size(GB)                                                     \n",
      "30GB grid index skyline              53                  3   \n",
      "40GB grid index skyline              55                  3   \n",
      "50GB grid index skyline              67                  3   \n",
      "60GB grid index skyline              64                  4   \n",
      "70GB grid index skyline              71                  3   \n",
      "\n",
      "                                    application_number  \n",
      "Size(GB)                                                \n",
      "30GB grid index skyline  application1552397085974_0003  \n",
      "40GB grid index skyline  application1552397085974_0004  \n",
      "50GB grid index skyline  application1552397085974_0006  \n",
      "60GB grid index skyline  application1552397085974_0008  \n",
      "70GB grid index skyline  application1552397085974_0010  \n"
     ]
    }
   ],
   "source": [
    "#final_data=pd.DataFrame(columns=['map_time(ms)','reduce_time(ms)','total_time(s)','cpu_time(ms)','diff_time(s)','map_start_diff(s)','map_end_diff(s)','filter_end_diff(s)','application_number'],index=['30GB non-indexed skyline','30GB grid index skyline','40GB non-indexed skyline','40GB grid index skyline','50GB non-indexed skyline','50GB grid index skyline','60GB non-indexed skyline','60GB grid index skyline','70GB non-indexed skyline','70GB grid index skyline','80GB non-indexed skyline','80GB grid index skyline'])\n",
    "#final_data=pd.DataFrame(columns=['map_time(ms)','reduce_time(ms)','total_time(s)','cpu_time(ms)','diff_time(s)','map_start_diff(s)','map_end_diff(s)','filter_end_diff(s)','application_number'],index=['30GB grid index skyline','40GB grid index skyline','50GB grid index skyline','60GB grid index skyline','70GB grid index skyline'])\n",
    "final_data=pd.DataFrame(columns=['map_time(ms)','reduce_time(ms)','total_time(s)','cpu_time(ms)','diff_time(s)','map_start_diff(s)','map_end_diff(s)','filter_end_diff(s)','application_number'],index=['50GB grid indexing operation'])\n",
    "final_data.index.name=\"Size(GB)\"\n",
    "#path_graphs='C:/Tejas/PESU/CCBD_researchh/New Tests/global_index_skyline/graphs/'\n",
    "\n",
    "#files=['c_50gb_skyline_normal_','c_50gb_skyline_grid_','c_50gb_skyline_rtree_','c_60gb_skyline_normal_','c_60gb_skyline_grid_','c_60gb_skyline_rtree_','c_70gb_skyline_normal_','c_70gb_skyline_grid_','c_70gb_skyline_rtree_']\n",
    "#files=['c_30gb_skyline','c_30gb_skyline_grid','c_40gb_skyline','c_40gb_skyline_grid','c_50gb_skyline','c_50gb_skyline_grid','c_60gb_skyline','c_60gb_skyline_grid','c_70gb_skyline','c_70gb_skyline_grid','c_80gb_skyline','c_80gb_skyline_grid']\n",
    "files=['c_30gb_skyline_grid','c_40gb_skyline_grid','c_50gb_skyline_grid','c_60gb_skyline_grid','c_70gb_skyline_grid']\n",
    "path=\"C:/Tejas/PESU/CCBD_researchh/New Tests/skyline_ssd/FINAL DATA CPU UTIL\"+'/'\n",
    "counter=0\n",
    "#HDD stats\n",
    "#tests=['test7_8vcores_10vcores','test8_8vcores_10vcores','test9_8vcores_10vcores_reduce1','test10_8vcores_10vcores_reduce2','test12_8vcores_10vcores_reduce3','test13_8vcores_10vcores_reduce3_11520MB']\n",
    "tests=['test16_8vcores_10vcores_reduce1_12920MB']\n",
    "#tests=['test16_8vcores_10vcores_reduce1_12920MB','test14_8vcores_10vcores_reduce1_11820MB']\n",
    "all_tests=['test1','test2']\n",
    "for test in tests:\n",
    "    counter=0\n",
    "    for data in final_data.index:\n",
    "        for col in final_data.columns:\n",
    "            final_data.loc[str(data),col]=[]\n",
    "    #print(final_data)\n",
    "    for test_num in all_tests:\n",
    "        print(test_num)\n",
    "        counter=0\n",
    "        for data in final_data.index:\n",
    "            for col in final_data.columns:\n",
    "                final_data.loc[str(data),col]=[]\n",
    "        for data in final_data.index:\n",
    "            #open job counters\n",
    "            fp=open(path+test+\"/\"+test_num+'/master/'+files[counter],'r')\n",
    "            string=fp.read()\n",
    "            \n",
    "            #Look for map time\n",
    "            map_time=int(string[string.find('Total time spent by all map tasks (ms)'):].split(\"\\n\")[0].split(\"=\")[1])\n",
    "            \n",
    "            #Look for reduce time\n",
    "            reduce_time=int(string[string.find('Total time spent by all reduce tasks (ms)'):].split(\"\\n\")[0].split(\"=\")[1])\n",
    "            \n",
    "            #look for cputime\n",
    "            cpu_time=int(string[string.find('CPU time spent (ms)'):].split(\"\\n\")[0].split(\"=\")[1])\n",
    "            \n",
    "            #Look for total time\n",
    "            total_time=float(int(string[string.find('Total time: '):].split(\"\\n\")[0].split(\":\")[1].strip().split()[0])/1000)\n",
    "            \n",
    "            #Look for start time\n",
    "            start_time=string.split(\"\\n\")[0].split(\" \")[0]+\" \"+string.split(\"\\n\")[0].split(\" \")[1]\n",
    "            start_job_time=string[string.find(\"Running job:\"):].split(\"\\n\")[1].split(\" \")[0]+\" \"+string[string.find(\"Running job:\"):].split(\"\\n\")[1].split(\" \")[1]\n",
    "            d1=datetime.strptime(start_time,\"%y/%m/%d %H:%M:%S\")\n",
    "            d2=datetime.strptime(start_job_time,\"%y/%m/%d %H:%M:%S\")\n",
    "            time_skip=d2-d1\n",
    "            #time_skip=int(time_skip.split(\":\")[0]*3600) + int(time_skip.split(\":\")[1]*60) +int(time_skip.split(\":\")[2]) \n",
    "            time_skip=time_skip.total_seconds()\n",
    "            \n",
    "            #Look for filter phase end time\n",
    "            filter_end_time=string[:string.find(\"Spatial filter function matched with\")].split(\"\\n\")[-1].split(\" \")[0]+ \" \"+string[:string.find(\"Spatial filter function matched with\")].split(\"\\n\")[-1].split(\" \")[1]\n",
    "            d2=datetime.strptime(filter_end_time,\"%y/%m/%d %H:%M:%S\")\n",
    "            time_skip_filter_end=d2-d1\n",
    "            time_skip_filter_end=time_skip_filter_end.total_seconds()\n",
    "            \n",
    "            \n",
    "            #Look for map start time\n",
    "            map_start_time=string[string.find(\"running in uber mode : false\"):].split(\"\\n\")[1].split(\" \")[0]+ \" \"+string[string.find(\"running in uber mode : false\"):].split(\"\\n\")[1].split(\" \")[1]\n",
    "            d2=datetime.strptime(map_start_time,\"%y/%m/%d %H:%M:%S\")\n",
    "            time_skip_map_start=d2-d1\n",
    "            time_skip_map_start=time_skip_map_start.total_seconds()\n",
    "            \n",
    "            #Look for map end time\n",
    "            map_end_time=string[:string.find(\"INFO mapreduce.Job:  map 100%\")].split(\"\\n\")[-1].split(\" \")[0]+ \" \"+string[:string.find(\"INFO mapreduce.Job:  map 100%\")].split(\"\\n\")[-1].split(\" \")[1]\n",
    "            d2=datetime.strptime(map_end_time,\"%y/%m/%d %H:%M:%S\")\n",
    "            time_skip_map_end=d2-d1\n",
    "            time_skip_map_end=time_skip_map_end.total_seconds()\n",
    "            \n",
    "            #Look for application number\n",
    "            application_number=string[string.find(\"Running job:\"):].split(\"\\n\")[0].split(\" \")[2]\n",
    "            application_number='application'+application_number.split(\"_\",maxsplit=1)[1]\n",
    "            \n",
    "            \n",
    "            final_data.loc[str(data),'map_time(ms)'].append(map_time)\n",
    "            final_data.loc[str(data),'reduce_time(ms)'].append(reduce_time)\n",
    "            final_data.loc[str(data),'total_time(s)'].append(total_time)\n",
    "            final_data.loc[str(data),'cpu_time(ms)'].append(cpu_time)\n",
    "            final_data.loc[str(data),'diff_time(s)'].append(time_skip)\n",
    "            final_data.loc[str(data),'map_start_diff(s)'].append(time_skip_map_start)\n",
    "            final_data.loc[str(data),'map_end_diff(s)'].append(time_skip_map_end)\n",
    "            final_data.loc[str(data),'filter_end_diff(s)'].append(time_skip_filter_end)\n",
    "            final_data.loc[str(data),'application_number']=application_number\n",
    "\n",
    "            counter=counter+1\n",
    "        for data in final_data.index:\n",
    "            final_data.loc[str(data),'map_time(ms)']=np.average(final_data.loc[str(data),'map_time(ms)'])\n",
    "            final_data.loc[str(data),'reduce_time(ms)']=np.average(final_data.loc[str(data),'reduce_time(ms)'])\n",
    "            final_data.loc[str(data),'total_time(s)']=np.average(final_data.loc[str(data),'total_time(s)'])\n",
    "            final_data.loc[str(data),'cpu_time(ms)']=np.average(final_data.loc[str(data),'cpu_time(ms)'])\n",
    "            final_data.loc[str(data),'diff_time(s)']=np.average(final_data.loc[str(data),'diff_time(s)'])\n",
    "            final_data.loc[str(data),'map_start_diff(s)']=np.average(final_data.loc[str(data),'map_start_diff(s)'])\n",
    "            final_data.loc[str(data),'map_end_diff(s)']=np.average(final_data.loc[str(data),'map_end_diff(s)'])\n",
    "            final_data.loc[str(data),'filter_end_diff(s)']=np.average(final_data.loc[str(data),'filter_end_diff(s)'])\n",
    "            #final_data.loc[str(data),'application_number']=np.average(final_data.loc[str(data),'application_number'])\n",
    "        \n",
    "        final_data.to_excel(path+'ssd_counters_'+test+\"_\"+str(test_num)+'.xlsx')\n",
    "        print(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1\n",
      "             total_time(s)             application_number sampling_time(s)\n",
      "Size(GB)                                                                  \n",
      "AREA_LM_2015        39.956  application1558636471958_0001            37.89\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "#For parsing Grid Indexing operation\n",
    "\n",
    "#final_data=pd.DataFrame(columns=['map_time(ms)','reduce_time(ms)','total_time(s)','cpu_time(ms)','diff_time(s)','map_start_diff(s)','map_end_diff(s)','filter_end_diff(s)','application_number'],index=['30GB non-indexed skyline','30GB grid index skyline','40GB non-indexed skyline','40GB grid index skyline','50GB non-indexed skyline','50GB grid index skyline','60GB non-indexed skyline','60GB grid index skyline','70GB non-indexed skyline','70GB grid index skyline','80GB non-indexed skyline','80GB grid index skyline'])\n",
    "#final_data=pd.DataFrame(columns=['map_time(ms)','reduce_time(ms)','total_time(s)','cpu_time(ms)','diff_time(s)','map_start_diff(s)','map_end_diff(s)','filter_end_diff(s)','application_number'],index=['30GB grid index skyline','40GB grid index skyline','50GB grid index skyline','60GB grid index skyline','70GB grid index skyline'])\n",
    "final_data=pd.DataFrame(columns=['total_time(s)','application_number','sampling_time(s)'],index=['AREA_LM_2015'])\n",
    "final_data.index.name=\"Size(GB)\"\n",
    "#path_graphs='C:/Tejas/PESU/CCBD_researchh/New Tests/global_index_skyline/graphs/'\n",
    "\n",
    "#files=['c_50gb_skyline_normal_','c_50gb_skyline_grid_','c_50gb_skyline_rtree_','c_60gb_skyline_normal_','c_60gb_skyline_grid_','c_60gb_skyline_rtree_','c_70gb_skyline_normal_','c_70gb_skyline_grid_','c_70gb_skyline_rtree_']\n",
    "#files=['c_30gb_skyline','c_30gb_skyline_grid','c_40gb_skyline','c_40gb_skyline_grid','c_50gb_skyline','c_50gb_skyline_grid','c_60gb_skyline','c_60gb_skyline_grid','c_70gb_skyline','c_70gb_skyline_grid','c_80gb_skyline','c_80gb_skyline_grid']\n",
    "#files=['c_30gb_skyline_grid','c_40gb_skyline_grid','c_50gb_skyline_grid','c_60gb_skyline_grid','c_70gb_skyline_grid']\n",
    "#iles=['c_30gb_index_grid','c_40gb_index_grid','c_50gb_index_grid','c_60gb_index_grid','c_70gb_index_grid']\n",
    "files=['c_AREA_LM_2015_index_grid']\n",
    "\n",
    "#path=\"F:/Recovery lenovo laptop/Tejas/PESU/CCBD_researchh/New Tests/grid_indexing/global_index_grid_indexing/FINAL DATA CPU UTIL\"+'/'\n",
    "path=\"F:/Recovery lenovo laptop/Tejas/PESU/CCBD_researchh/New Tests/real_datasets/indexing/\"\n",
    "counter=0\n",
    "#HDD stats\n",
    "#tests=['test7_8vcores_10vcores','test8_8vcores_10vcores','test9_8vcores_10vcores_reduce1','test10_8vcores_10vcores_reduce2','test12_8vcores_10vcores_reduce3','test13_8vcores_10vcores_reduce3_11520MB']\n",
    "tests=['hdd']\n",
    "#tests=['test16_8vcores_10vcores_reduce1_12920MB','test14_8vcores_10vcores_reduce1_11820MB']\n",
    "all_tests=['test1']\n",
    "for test in tests:\n",
    "    counter=0\n",
    "    for data in final_data.index:\n",
    "        for col in final_data.columns:\n",
    "            final_data.loc[str(data),col]=[]\n",
    "    #print(final_data)\n",
    "    for test_num in all_tests:\n",
    "        print(test_num)\n",
    "        counter=0\n",
    "        for data in final_data.index:\n",
    "            for col in final_data.columns:\n",
    "                final_data.loc[str(data),col]=[]\n",
    "        for data in final_data.index:\n",
    "            #open job counters\n",
    "            fp=open(path+test+\"/\"+test_num+'/master/'+files[counter],'r')\n",
    "            string=fp.read()\n",
    "            \n",
    "            #Look for map time\n",
    "#             map_time=int(string[string.find('Total time spent by all map tasks (ms)'):].split(\"\\n\")[0].split(\"=\")[1])\n",
    "            \n",
    "            #Look for reduce time\n",
    "#             reduce_time=int(string[string.find('Total time spent by all reduce tasks (ms)'):].split(\"\\n\")[0].split(\"=\")[1])\n",
    "            \n",
    "            #look for cputime\n",
    "#             cpu_time=int(string[string.find('CPU time spent (ms)'):].split(\"\\n\")[0].split(\"=\")[1])\n",
    "            \n",
    "            #Look for total time\n",
    "            total_time=float(int(string[string.find('Total indexing time in millis'):].split(\"\\n\")[0].split(\" \")[-1])/1000)\n",
    "            \n",
    "            \n",
    "#             Look for start time\n",
    "            start_time=string.split(\"\\n\")[0].split(\" \")[0]+\" \"+string.split(\"\\n\")[0].split(\" \")[1]\n",
    "#             start_job_time=string[string.find(\"Running job:\"):].split(\"\\n\")[1].split(\" \")[0]+\" \"+string[string.find(\"Running job:\"):].split(\"\\n\")[1].split(\" \")[1]\n",
    "            d1=datetime.strptime(start_time,\"%y/%m/%d %H:%M:%S\")\n",
    "             \n",
    "            #Look for sampling time\n",
    "            sampling_time=float(int(string[string.find('Total time for sampling in millis:'):].split(\"\\n\")[0].split(\":\")[1].strip())/1000)\n",
    "            \n",
    "            #Look for application number\n",
    "            application_number=string[string.find(\"Running job:\"):].split(\"\\n\")[0].split(\" \")[2]\n",
    "            application_number='application'+application_number.split(\"_\",maxsplit=1)[1]\n",
    "            \n",
    "            \n",
    "#             final_data.loc[str(data),'map_time(ms)'].append(map_time)\n",
    "#             final_data.loc[str(data),'reduce_time(ms)'].append(reduce_time)\n",
    "            final_data.loc[str(data),'total_time(s)'].append(total_time)\n",
    "#             final_data.loc[str(data),'cpu_time(ms)'].append(cpu_time)\n",
    "#             final_data.loc[str(data),'diff_time(s)'].append(time_skip)\n",
    "#             final_data.loc[str(data),'map_start_diff(s)'].append(time_skip_map_start)\n",
    "#             final_data.loc[str(data),'map_end_diff(s)'].append(time_skip_map_end)\n",
    "#             final_data.loc[str(data),'filter_end_diff(s)'].append(time_skip_filter_end)\n",
    "            final_data.loc[str(data),'application_number']=application_number\n",
    "            final_data.loc[str(data),'sampling_time(s)']=sampling_time\n",
    "\n",
    "            counter=counter+1\n",
    "        for data in final_data.index:\n",
    "#             final_data.loc[str(data),'map_time(ms)']=np.average(final_data.loc[str(data),'map_time(ms)'])\n",
    "#             final_data.loc[str(data),'reduce_time(ms)']=np.average(final_data.loc[str(data),'reduce_time(ms)'])\n",
    "            final_data.loc[str(data),'total_time(s)']=np.average(final_data.loc[str(data),'total_time(s)'])\n",
    "            final_data.loc[str(data),'sampling_time(s)']=np.average(final_data.loc[str(data),'sampling_time(s)'])\n",
    "\n",
    "#             final_data.loc[str(data),'cpu_time(ms)']=np.average(final_data.loc[str(data),'cpu_time(ms)'])\n",
    "#             final_data.loc[str(data),'diff_time(s)']=np.average(final_data.loc[str(data),'diff_time(s)'])\n",
    "#             final_data.loc[str(data),'map_start_diff(s)']=np.average(final_data.loc[str(data),'map_start_diff(s)'])\n",
    "#             final_data.loc[str(data),'map_end_diff(s)']=np.average(final_data.loc[str(data),'map_end_diff(s)'])\n",
    "#             final_data.loc[str(data),'filter_end_diff(s)']=np.average(final_data.loc[str(data),'filter_end_diff(s)'])\n",
    "            #final_data.loc[str(data),'application_number']=np.average(final_data.loc[str(data),'application_number'])\n",
    "        \n",
    "        final_data.to_excel(path+'ssd_counters_'+test+\"_\"+str(test_num)+'_grid_index.xlsx')\n",
    "        print(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test3\n",
      "                      total_time(s)             application_number  \\\n",
      "Size(GB)                                                             \n",
      "200MB X 400MB Grid DJ       4398.48  application1553270797903_0009   \n",
      "\n",
      "                      filter_end_diff(s)  \n",
      "Size(GB)                                  \n",
      "200MB X 400MB Grid DJ                  2  \n"
     ]
    }
   ],
   "source": [
    "#Distributed Join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "#final_data=pd.DataFrame(columns=['map_time(ms)','reduce_time(ms)','total_time(s)','cpu_time(ms)','diff_time(s)','map_start_diff(s)','map_end_diff(s)','filter_end_diff(s)','application_number'],index=['30GB non-indexed skyline','30GB grid index skyline','40GB non-indexed skyline','40GB grid index skyline','50GB non-indexed skyline','50GB grid index skyline','60GB non-indexed skyline','60GB grid index skyline','70GB non-indexed skyline','70GB grid index skyline','80GB non-indexed skyline','80GB grid index skyline'])\n",
    "#final_data=pd.DataFrame(columns=['map_time(ms)','reduce_time(ms)','total_time(s)','cpu_time(ms)','diff_time(s)','map_start_diff(s)','map_end_diff(s)','filter_end_diff(s)','application_number'],index=['30GB grid index skyline','40GB grid index skyline','50GB grid index skyline','60GB grid index skyline','70GB grid index skyline'])\n",
    "final_data=pd.DataFrame(columns=['total_time(s)','application_number','filter_end_diff(s)'],index=['200MB X 400MB Grid DJ'])\n",
    "final_data.index.name=\"Size(GB)\"\n",
    "#path_graphs='C:/Tejas/PESU/CCBD_researchh/New Tests/global_index_skyline/graphs/'\n",
    "\n",
    "#files=['c_50gb_skyline_normal_','c_50gb_skyline_grid_','c_50gb_skyline_rtree_','c_60gb_skyline_normal_','c_60gb_skyline_grid_','c_60gb_skyline_rtree_','c_70gb_skyline_normal_','c_70gb_skyline_grid_','c_70gb_skyline_rtree_']\n",
    "#files=['c_30gb_skyline','c_30gb_skyline_grid','c_40gb_skyline','c_40gb_skyline_grid','c_50gb_skyline','c_50gb_skyline_grid','c_60gb_skyline','c_60gb_skyline_grid','c_70gb_skyline','c_70gb_skyline_grid','c_80gb_skyline','c_80gb_skyline_grid']\n",
    "#files=['c_30gb_skyline_grid','c_40gb_skyline_grid','c_50gb_skyline_grid','c_60gb_skyline_grid','c_70gb_skyline_grid']\n",
    "files=['c_200mb_400mb_dj_grid']\n",
    "path=\"/media/ubuntu/Seagate Backup Plus Drive/Recovery lenovo laptop/Tejas/PESU/CCBD_researchh/New Tests/dj/global_index_dj_ssd/FINAL DATA CPU UTIL\"+'/'\n",
    "counter=0\n",
    "#HDD stats\n",
    "#tests=['test7_8vcores_10vcores','test8_8vcores_10vcores','test9_8vcores_10vcores_reduce1','test10_8vcores_10vcores_reduce2','test12_8vcores_10vcores_reduce3','test13_8vcores_10vcores_reduce3_11520MB']\n",
    "tests=['test16_8vcores_10vcores_reduce1_12920MB']\n",
    "#tests=['test16_8vcores_10vcores_reduce1_12920MB','test14_8vcores_10vcores_reduce1_11820MB']\n",
    "all_tests=['test3']\n",
    "for test in tests:\n",
    "    counter=0\n",
    "    for data in final_data.index:\n",
    "        for col in final_data.columns:\n",
    "            final_data.loc[str(data),col]=[]\n",
    "    #print(final_data)\n",
    "    for test_num in all_tests:\n",
    "        print(test_num)\n",
    "        counter=0\n",
    "        for data in final_data.index:\n",
    "            for col in final_data.columns:\n",
    "                final_data.loc[str(data),col]=[]\n",
    "        for data in final_data.index:\n",
    "            #open job counters\n",
    "            fp=open(path+test+\"/\"+test_num+'/master/'+files[counter],'r')\n",
    "            string=fp.read()\n",
    "            \n",
    "            #Look for map time\n",
    "#             map_time=int(string[string.find('Total time spent by all map tasks (ms)'):].split(\"\\n\")[0].split(\"=\")[1])\n",
    "            \n",
    "            #Look for reduce time\n",
    "#             reduce_time=int(string[string.find('Total time spent by all reduce tasks (ms)'):].split(\"\\n\")[0].split(\"=\")[1])\n",
    "            \n",
    "            #look for cputime\n",
    "#             cpu_time=int(string[string.find('CPU time spent (ms)'):].split(\"\\n\")[0].split(\"=\")[1])\n",
    "            \n",
    "            #Look for total time\n",
    "            total_time=float(int(string[string.find('Join time'):].split(\"\\n\")[0].split(\" \")[-2])/1000)\n",
    "            \n",
    "            \n",
    "#             Look for start time\n",
    "            start_time=string.split(\"\\n\")[0].split(\" \")[0]+\" \"+string.split(\"\\n\")[0].split(\" \")[1]\n",
    "#             start_job_time=string[string.find(\"Running job:\"):].split(\"\\n\")[1].split(\" \")[0]+\" \"+string[string.find(\"Running job:\"):].split(\"\\n\")[1].split(\" \")[1]\n",
    "            d1=datetime.strptime(start_time,\"%y/%m/%d %H:%M:%S\")\n",
    "             \n",
    "            #Look for filter end time\n",
    "            filter_end_time=string[:string.find('mapred.BinarySpatialInputFormat:')].split(\"\\n\")[-1].split(\" \")[0]+\" \"+string[:string.find('mapred.BinarySpatialInputFormat:')].split(\"\\n\")[-1].split(\" \")[1]\n",
    "            d2=datetime.strptime(filter_end_time,\"%y/%m/%d %H:%M:%S\")\n",
    "            time_skip_filter_end=d2-d1\n",
    "            time_skip_filter_end=time_skip_filter_end.total_seconds()\n",
    "            \n",
    "            #Look for application number\n",
    "            application_number=string[string.find(\"Running job:\"):].split(\"\\n\")[0].split(\" \")[2]\n",
    "            application_number='application'+application_number.split(\"_\",maxsplit=1)[1]\n",
    "            \n",
    "            \n",
    "#             final_data.loc[str(data),'map_time(ms)'].append(map_time)\n",
    "#             final_data.loc[str(data),'reduce_time(ms)'].append(reduce_time)\n",
    "            final_data.loc[str(data),'total_time(s)'].append(total_time)\n",
    "#             final_data.loc[str(data),'cpu_time(ms)'].append(cpu_time)\n",
    "#             final_data.loc[str(data),'diff_time(s)'].append(time_skip)\n",
    "#             final_data.loc[str(data),'map_start_diff(s)'].append(time_skip_map_start)\n",
    "#             final_data.loc[str(data),'map_end_diff(s)'].append(time_skip_map_end)\n",
    "#             final_data.loc[str(data),'filter_end_diff(s)'].append(time_skip_filter_end)\n",
    "            final_data.loc[str(data),'application_number']=application_number\n",
    "            final_data.loc[str(data),'filter_end_diff(s)']=time_skip_filter_end\n",
    "\n",
    "            counter=counter+1\n",
    "        for data in final_data.index:\n",
    "#             final_data.loc[str(data),'map_time(ms)']=np.average(final_data.loc[str(data),'map_time(ms)'])\n",
    "#             final_data.loc[str(data),'reduce_time(ms)']=np.average(final_data.loc[str(data),'reduce_time(ms)'])\n",
    "            final_data.loc[str(data),'total_time(s)']=np.average(final_data.loc[str(data),'total_time(s)'])\n",
    "            final_data.loc[str(data),'filter_end_diff(s)']=np.average(final_data.loc[str(data),'filter_end_diff(s)'])\n",
    "\n",
    "#             final_data.loc[str(data),'cpu_time(ms)']=np.average(final_data.loc[str(data),'cpu_time(ms)'])\n",
    "#             final_data.loc[str(data),'diff_time(s)']=np.average(final_data.loc[str(data),'diff_time(s)'])\n",
    "#             final_data.loc[str(data),'map_start_diff(s)']=np.average(final_data.loc[str(data),'map_start_diff(s)'])\n",
    "#             final_data.loc[str(data),'map_end_diff(s)']=np.average(final_data.loc[str(data),'map_end_diff(s)'])\n",
    "#             final_data.loc[str(data),'filter_end_diff(s)']=np.average(final_data.loc[str(data),'filter_end_diff(s)'])\n",
    "            #final_data.loc[str(data),'application_number']=np.average(final_data.loc[str(data),'application_number'])\n",
    "        \n",
    "        final_data.to_excel(path+'ssd_counters_'+test+\"_\"+str(test_num)+'_dj_grid.xlsx')\n",
    "        print(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1\n",
      "                             map_time(ms) reduce_time(ms) total_time(s)  \\\n",
      "Size(GB)                                                                  \n",
      "30GB grid indexed convexhull  1.03802e+06           52565        87.388   \n",
      "40GB grid indexed convexhull  1.15592e+06           59542        94.807   \n",
      "60GB grid indexed convexhull  1.44332e+06           81015       120.906   \n",
      "70GB grid indexed convexhull  1.58794e+06           91246       127.318   \n",
      "\n",
      "                             cpu_time(ms) diff_time(s) map_start_diff(s)  \\\n",
      "Size(GB)                                                                   \n",
      "30GB grid indexed convexhull       528290           10                10   \n",
      "40GB grid indexed convexhull       597770           10                10   \n",
      "60GB grid indexed convexhull       742940           13                13   \n",
      "70GB grid indexed convexhull       833200           10                10   \n",
      "\n",
      "                             map_end_diff(s) filter_end_diff(s)  \\\n",
      "Size(GB)                                                          \n",
      "30GB grid indexed convexhull              88                  4   \n",
      "40GB grid indexed convexhull              95                  4   \n",
      "60GB grid indexed convexhull             119                  5   \n",
      "70GB grid indexed convexhull             126                  3   \n",
      "\n",
      "                                         application_number  \n",
      "Size(GB)                                                     \n",
      "30GB grid indexed convexhull  application1555176033418_0018  \n",
      "40GB grid indexed convexhull  application1555176033418_0019  \n",
      "60GB grid indexed convexhull  application1555353051784_0001  \n",
      "70GB grid indexed convexhull  application1555353051784_0002  \n"
     ]
    }
   ],
   "source": [
    "#Convexhull\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "#final_data=pd.DataFrame(columns=['map_time(ms)','reduce_time(ms)','total_time(s)','cpu_time(ms)','diff_time(s)','map_start_diff(s)','map_end_diff(s)','filter_end_diff(s)','application_number'],index=['30GB non-indexed skyline','30GB grid index skyline','40GB non-indexed skyline','40GB grid index skyline','50GB non-indexed skyline','50GB grid index skyline','60GB non-indexed skyline','60GB grid index skyline','70GB non-indexed skyline','70GB grid index skyline','80GB non-indexed skyline','80GB grid index skyline'])\n",
    "#final_data=pd.DataFrame(columns=['map_time(ms)','reduce_time(ms)','total_time(s)','cpu_time(ms)','diff_time(s)','map_start_diff(s)','map_end_diff(s)','filter_end_diff(s)','application_number'],index=['30GB grid index skyline','40GB grid index skyline','50GB grid index skyline','60GB grid index skyline','70GB grid index skyline'])\n",
    "final_data=pd.DataFrame(columns=['map_time(ms)','reduce_time(ms)','total_time(s)','cpu_time(ms)','diff_time(s)','map_start_diff(s)','map_end_diff(s)','filter_end_diff(s)','application_number'],index=['30GB grid indexed convexhull','40GB grid indexed convexhull','60GB grid indexed convexhull','70GB grid indexed convexhull'])\n",
    "final_data.index.name=\"Size(GB)\"\n",
    "#path_graphs='C:/Tejas/PESU/CCBD_researchh/New Tests/global_index_skyline/graphs/'\n",
    "\n",
    "#files=['c_50gb_skyline_normal_','c_50gb_skyline_grid_','c_50gb_skyline_rtree_','c_60gb_skyline_normal_','c_60gb_skyline_grid_','c_60gb_skyline_rtree_','c_70gb_skyline_normal_','c_70gb_skyline_grid_','c_70gb_skyline_rtree_']\n",
    "#files=['c_30gb_skyline','c_30gb_skyline_grid','c_40gb_skyline','c_40gb_skyline_grid','c_50gb_skyline','c_50gb_skyline_grid','c_60gb_skyline','c_60gb_skyline_grid','c_70gb_skyline','c_70gb_skyline_grid','c_80gb_skyline','c_80gb_skyline_grid']\n",
    "#files=['c_30gb_skyline_grid','c_40gb_skyline_grid','c_50gb_skyline_grid','c_60gb_skyline_grid','c_70gb_skyline_grid']\n",
    "files=['c_30gb_convexhull_grid','c_40gb_convexhull_grid','c_60gb_convexhull_grid','c_70gb_convexhull_grid']\n",
    "path=\"D:/Recovery lenovo laptop/Tejas/PESU/CCBD_researchh/New Tests/convexhull/global_index_convexhull/FINAL DATA CPU UTIL\"+'/'\n",
    "counter=0\n",
    "#HDD stats\n",
    "#tests=['test7_8vcores_10vcores','test8_8vcores_10vcores','test9_8vcores_10vcores_reduce1','test10_8vcores_10vcores_reduce2','test12_8vcores_10vcores_reduce3','test13_8vcores_10vcores_reduce3_11520MB']\n",
    "tests=['test16_8vcores_10vcores_reduce1_12920MB']\n",
    "#tests=['test16_8vcores_10vcores_reduce1_12920MB','test14_8vcores_10vcores_reduce1_11820MB']\n",
    "all_tests=['test1']\n",
    "for test in tests:\n",
    "    counter=0\n",
    "    for data in final_data.index:\n",
    "        for col in final_data.columns:\n",
    "            final_data.loc[str(data),col]=[]\n",
    "    #print(final_data)\n",
    "    for test_num in all_tests:\n",
    "        print(test_num)\n",
    "        counter=0\n",
    "        for data in final_data.index:\n",
    "            for col in final_data.columns:\n",
    "                final_data.loc[str(data),col]=[]\n",
    "        for data in final_data.index:\n",
    "            #open job counters\n",
    "            fp=open(path+test+\"/\"+test_num+'/master/'+files[counter],'r')\n",
    "            string=fp.read()\n",
    "            \n",
    "            #Look for map time\n",
    "            map_time=int(string[string.find('Total time spent by all map tasks (ms)'):].split(\"\\n\")[0].split(\"=\")[1])\n",
    "            \n",
    "            #Look for reduce time\n",
    "            reduce_time=int(string[string.find('Total time spent by all reduce tasks (ms)'):].split(\"\\n\")[0].split(\"=\")[1])\n",
    "            \n",
    "            #look for cputime\n",
    "            cpu_time=int(string[string.find('CPU time spent (ms)'):].split(\"\\n\")[0].split(\"=\")[1])\n",
    "            \n",
    "            #Look for total time\n",
    "            total_time=float(int(string[string.find('Total time: '):].split(\"\\n\")[0].split(\":\")[1].strip().split()[0])/1000)\n",
    "            \n",
    "            #Look for start time\n",
    "            start_time=string.split(\"\\n\")[0].split(\" \")[0]+\" \"+string.split(\"\\n\")[0].split(\" \")[1]\n",
    "            start_job_time=string[string.find(\"Running job:\"):].split(\"\\n\")[1].split(\" \")[0]+\" \"+string[string.find(\"Running job:\"):].split(\"\\n\")[1].split(\" \")[1]\n",
    "            d1=datetime.strptime(start_time,\"%y/%m/%d %H:%M:%S\")\n",
    "            d2=datetime.strptime(start_job_time,\"%y/%m/%d %H:%M:%S\")\n",
    "            time_skip=d2-d1\n",
    "            #time_skip=int(time_skip.split(\":\")[0]*3600) + int(time_skip.split(\":\")[1]*60) +int(time_skip.split(\":\")[2]) \n",
    "            time_skip=time_skip.total_seconds()\n",
    "            \n",
    "            #Look for filter phase end time\n",
    "            filter_end_time=string[:string.find(\"Spatial filter function matched with\")].split(\"\\n\")[-1].split(\" \")[0]+ \" \"+string[:string.find(\"Spatial filter function matched with\")].split(\"\\n\")[-1].split(\" \")[1]\n",
    "            d2=datetime.strptime(filter_end_time,\"%y/%m/%d %H:%M:%S\")\n",
    "            time_skip_filter_end=d2-d1\n",
    "            time_skip_filter_end=time_skip_filter_end.total_seconds()\n",
    "            \n",
    "            \n",
    "            #Look for map start time\n",
    "            map_start_time=string[string.find(\"running in uber mode : false\"):].split(\"\\n\")[1].split(\" \")[0]+ \" \"+string[string.find(\"running in uber mode : false\"):].split(\"\\n\")[1].split(\" \")[1]\n",
    "            d2=datetime.strptime(map_start_time,\"%y/%m/%d %H:%M:%S\")\n",
    "            time_skip_map_start=d2-d1\n",
    "            time_skip_map_start=time_skip_map_start.total_seconds()\n",
    "            \n",
    "            #Look for map end time\n",
    "            map_end_time=string[:string.find(\"INFO mapreduce.Job:  map 100%\")].split(\"\\n\")[-1].split(\" \")[0]+ \" \"+string[:string.find(\"INFO mapreduce.Job:  map 100%\")].split(\"\\n\")[-1].split(\" \")[1]\n",
    "            d2=datetime.strptime(map_end_time,\"%y/%m/%d %H:%M:%S\")\n",
    "            time_skip_map_end=d2-d1\n",
    "            time_skip_map_end=time_skip_map_end.total_seconds()\n",
    "            \n",
    "            #Look for application number\n",
    "            application_number=string[string.find(\"Running job:\"):].split(\"\\n\")[0].split(\" \")[2]\n",
    "            application_number='application'+application_number.split(\"_\",maxsplit=1)[1]\n",
    "            \n",
    "            \n",
    "            final_data.loc[str(data),'map_time(ms)'].append(map_time)\n",
    "            final_data.loc[str(data),'reduce_time(ms)'].append(reduce_time)\n",
    "            final_data.loc[str(data),'total_time(s)'].append(total_time)\n",
    "            final_data.loc[str(data),'cpu_time(ms)'].append(cpu_time)\n",
    "            final_data.loc[str(data),'diff_time(s)'].append(time_skip)\n",
    "            final_data.loc[str(data),'map_start_diff(s)'].append(time_skip_map_start)\n",
    "            final_data.loc[str(data),'map_end_diff(s)'].append(time_skip_map_end)\n",
    "            final_data.loc[str(data),'filter_end_diff(s)'].append(time_skip_filter_end)\n",
    "            final_data.loc[str(data),'application_number']=application_number\n",
    "\n",
    "            counter=counter+1\n",
    "        for data in final_data.index:\n",
    "            final_data.loc[str(data),'map_time(ms)']=np.average(final_data.loc[str(data),'map_time(ms)'])\n",
    "            final_data.loc[str(data),'reduce_time(ms)']=np.average(final_data.loc[str(data),'reduce_time(ms)'])\n",
    "            final_data.loc[str(data),'total_time(s)']=np.average(final_data.loc[str(data),'total_time(s)'])\n",
    "            final_data.loc[str(data),'cpu_time(ms)']=np.average(final_data.loc[str(data),'cpu_time(ms)'])\n",
    "            final_data.loc[str(data),'diff_time(s)']=np.average(final_data.loc[str(data),'diff_time(s)'])\n",
    "            final_data.loc[str(data),'map_start_diff(s)']=np.average(final_data.loc[str(data),'map_start_diff(s)'])\n",
    "            final_data.loc[str(data),'map_end_diff(s)']=np.average(final_data.loc[str(data),'map_end_diff(s)'])\n",
    "            final_data.loc[str(data),'filter_end_diff(s)']=np.average(final_data.loc[str(data),'filter_end_diff(s)'])\n",
    "            #final_data.loc[str(data),'application_number']=np.average(final_data.loc[str(data),'application_number'])\n",
    "        \n",
    "        final_data.to_excel(path+'ssd_counters_'+test+\"_\"+str(test_num)+'_convexhull_grid.xlsx')\n",
    "        print(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
